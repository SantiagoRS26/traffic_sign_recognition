
Entrenando fold 1/2 para CNN Modelo 1
c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\keras\src\layers\convolutional\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
Epoch 1/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m3s[0m 11ms/step - accuracy: 0.2699 - loss: 2.8643 - val_accuracy: 0.7943 - val_loss: 0.8116
Epoch 2/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 11ms/step - accuracy: 0.8580 - loss: 0.5895 - val_accuracy: 0.9294 - val_loss: 0.3220
Epoch 3/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 11ms/step - accuracy: 0.9369 - loss: 0.2676 - val_accuracy: 0.9549 - val_loss: 0.2071
Epoch 4/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 11ms/step - accuracy: 0.9560 - loss: 0.1894 - val_accuracy: 0.9565 - val_loss: 0.1896
Epoch 5/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 10ms/step - accuracy: 0.9706 - loss: 0.1178 - val_accuracy: 0.9688 - val_loss: 0.1481
Epoch 6/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 10ms/step - accuracy: 0.9791 - loss: 0.0900 - val_accuracy: 0.9654 - val_loss: 0.1508
Epoch 7/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 11ms/step - accuracy: 0.9798 - loss: 0.0802 - val_accuracy: 0.9709 - val_loss: 0.1317
Epoch 8/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 10ms/step - accuracy: 0.9874 - loss: 0.0566 - val_accuracy: 0.9789 - val_loss: 0.1065
Epoch 9/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 9ms/step - accuracy: 0.9870 - loss: 0.0491 - val_accuracy: 0.9660 - val_loss: 0.1671
Epoch 10/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 10ms/step - accuracy: 0.9842 - loss: 0.0662 - val_accuracy: 0.9790 - val_loss: 0.1141
Exactitud en fold 1: 0.9790

Entrenando fold 2/2 para CNN Modelo 1
Epoch 1/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m3s[0m 10ms/step - accuracy: 0.3023 - loss: 2.7598 - val_accuracy: 0.8650 - val_loss: 0.6000
Epoch 2/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 10ms/step - accuracy: 0.8902 - loss: 0.4623 - val_accuracy: 0.9393 - val_loss: 0.2653
Epoch 3/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 10ms/step - accuracy: 0.9471 - loss: 0.2225 - val_accuracy: 0.9502 - val_loss: 0.2009
Epoch 4/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 10ms/step - accuracy: 0.9740 - loss: 0.1207 - val_accuracy: 0.9649 - val_loss: 0.1584
Epoch 5/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 10ms/step - accuracy: 0.9810 - loss: 0.0834 - val_accuracy: 0.9641 - val_loss: 0.1558
Epoch 6/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 10ms/step - accuracy: 0.9832 - loss: 0.0737 - val_accuracy: 0.9724 - val_loss: 0.1315
Epoch 7/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 10ms/step - accuracy: 0.9884 - loss: 0.0492 - val_accuracy: 0.9747 - val_loss: 0.1232
Epoch 8/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 10ms/step - accuracy: 0.9902 - loss: 0.0383 - val_accuracy: 0.9743 - val_loss: 0.1261
Epoch 9/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 10ms/step - accuracy: 0.9930 - loss: 0.0270 - val_accuracy: 0.9703 - val_loss: 0.1458
Epoch 10/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 10ms/step - accuracy: 0.9870 - loss: 0.0454 - val_accuracy: 0.9720 - val_loss: 0.1355
Exactitud en fold 2: 0.9720

Exactitud promedio para CNN Modelo 1: 0.9755 +/- 0.0035

Entrenando fold 1/2 para CNN Modelo 2
Epoch 1/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m6s[0m 23ms/step - accuracy: 0.2181 - loss: 2.9858 - val_accuracy: 0.8960 - val_loss: 0.4163
Epoch 2/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.8419 - loss: 0.5512 - val_accuracy: 0.9673 - val_loss: 0.1345
Epoch 3/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.9260 - loss: 0.2561 - val_accuracy: 0.9828 - val_loss: 0.0757
Epoch 4/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.9481 - loss: 0.1754 - val_accuracy: 0.9836 - val_loss: 0.0623
Epoch 5/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.9627 - loss: 0.1290 - val_accuracy: 0.9890 - val_loss: 0.0493
Epoch 6/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.9678 - loss: 0.1066 - val_accuracy: 0.9866 - val_loss: 0.0486
Epoch 7/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.9704 - loss: 0.0958 - val_accuracy: 0.9893 - val_loss: 0.0434
Epoch 8/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 23ms/step - accuracy: 0.9753 - loss: 0.0796 - val_accuracy: 0.9908 - val_loss: 0.0375
Epoch 9/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.9839 - loss: 0.0573 - val_accuracy: 0.9910 - val_loss: 0.0355
Epoch 10/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.9827 - loss: 0.0535 - val_accuracy: 0.9896 - val_loss: 0.0380
Exactitud en fold 1: 0.9896

Entrenando fold 2/2 para CNN Modelo 2
Epoch 1/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m6s[0m 22ms/step - accuracy: 0.1916 - loss: 3.0687 - val_accuracy: 0.8714 - val_loss: 0.4943
Epoch 2/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 21ms/step - accuracy: 0.8143 - loss: 0.6429 - val_accuracy: 0.9571 - val_loss: 0.1636
Epoch 3/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.9134 - loss: 0.2878 - val_accuracy: 0.9774 - val_loss: 0.1012
Epoch 4/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.9425 - loss: 0.1967 - val_accuracy: 0.9791 - val_loss: 0.0839
Epoch 5/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.9537 - loss: 0.1442 - val_accuracy: 0.9822 - val_loss: 0.0726
Epoch 6/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.9639 - loss: 0.1147 - val_accuracy: 0.9821 - val_loss: 0.0656
Epoch 7/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.9695 - loss: 0.1021 - val_accuracy: 0.9828 - val_loss: 0.0711
Epoch 8/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.9709 - loss: 0.0986 - val_accuracy: 0.9867 - val_loss: 0.0534
Epoch 9/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.9762 - loss: 0.0795 - val_accuracy: 0.9869 - val_loss: 0.0523
Epoch 10/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.9797 - loss: 0.0662 - val_accuracy: 0.9878 - val_loss: 0.0527
Exactitud en fold 2: 0.9878

Exactitud promedio para CNN Modelo 2: 0.9887 +/- 0.0009
[34m[1mwandb[0m: [33mWARNING[0m WandbCallback is deprecated and will be removed in a future release. Please use the WandbMetricsLogger, WandbModelCheckpoint, and WandbEvalCallback callbacks instead. See https://docs.wandb.ai/guides/integrations/keras for more information.
[34m[1mwandb[0m: [33mWARNING[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
Epoch 1/10
[31mERROR[0m:    Exception in ASGI application
Traceback (most recent call last):
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\uvicorn\protocols\http\h11_impl.py", line 403, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\uvicorn\middleware\proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\fastapi\applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\applications.py", line 113, in __call__
    await self.middleware_stack(scope, receive, send)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\middleware\errors.py", line 187, in __call__
    raise exc
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\middleware\errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\middleware\cors.py", line 93, in __call__
    await self.simple_response(scope, receive, send, request_headers=headers)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\middleware\cors.py", line 144, in simple_response
    await self.app(scope, receive, send)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\middleware\exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\routing.py", line 74, in app
    await response(scope, receive, send)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\responses.py", line 158, in __call__
    await self.background()
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\background.py", line 41, in __call__
    await task()
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\background.py", line 28, in __call__
    await run_in_threadpool(self.func, *self.args, **self.kwargs)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\concurrency.py", line 39, in run_in_threadpool
    return await anyio.to_thread.run_sync(func, *args)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\anyio\to_thread.py", line 56, in run_sync
    return await get_async_backend().run_sync_in_worker_thread(
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\anyio\_backends\_asyncio.py", line 2441, in run_sync_in_worker_thread
    return await future
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\anyio\_backends\_asyncio.py", line 943, in run
    result = context.run(func, *args)
  File "C:\Users\Josehp\Downloads\traffic_sign_recognition-main\traffic_sign_recognition-main\backend\app\utils\training_pipeline.py", line 167, in train_and_evaluate
    self.model.fit(
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\keras\src\utils\traceback_utils.py", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\wandb\integration\keras\keras.py", line 667, in on_train_batch_end
    wandb.run.summary["graph"] = wandb.Graph.from_keras(self.model)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\wandb\sdk\data_types\graph.py", line 357, in from_keras
    for in_layer in _nest(in_node.inbound_layers):
AttributeError: 'Node' object has no attribute 'inbound_layers'
[32mINFO[0m:     Shutting down
[32mINFO[0m:     Waiting for application shutdown.
[32mINFO[0m:     Application shutdown complete.
[32mINFO[0m:     Finished server process [[36m129828[0m]
