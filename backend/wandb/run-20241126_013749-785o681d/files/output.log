
Entrenando fold 1/2 para CNN Modelo 1
c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\keras\src\layers\convolutional\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
Epoch 1/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m3s[0m 11ms/step - accuracy: 0.2712 - loss: 2.8942 - val_accuracy: 0.8466 - val_loss: 0.6233
Epoch 2/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 10ms/step - accuracy: 0.8738 - loss: 0.5168 - val_accuracy: 0.9116 - val_loss: 0.3209
Epoch 3/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 10ms/step - accuracy: 0.9474 - loss: 0.2199 - val_accuracy: 0.9385 - val_loss: 0.2324
Epoch 4/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 10ms/step - accuracy: 0.9631 - loss: 0.1485 - val_accuracy: 0.9683 - val_loss: 0.1572
Epoch 5/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 10ms/step - accuracy: 0.9793 - loss: 0.0992 - val_accuracy: 0.9735 - val_loss: 0.1287
Epoch 6/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 10ms/step - accuracy: 0.9822 - loss: 0.0755 - val_accuracy: 0.9782 - val_loss: 0.1108
Epoch 7/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 10ms/step - accuracy: 0.9846 - loss: 0.0570 - val_accuracy: 0.9754 - val_loss: 0.1353
Epoch 8/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 10ms/step - accuracy: 0.9877 - loss: 0.0485 - val_accuracy: 0.9729 - val_loss: 0.1455
Epoch 9/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 11ms/step - accuracy: 0.9881 - loss: 0.0499 - val_accuracy: 0.9812 - val_loss: 0.1023
Epoch 10/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 11ms/step - accuracy: 0.9931 - loss: 0.0279 - val_accuracy: 0.9833 - val_loss: 0.0942
Exactitud en fold 1: 0.9833

Entrenando fold 2/2 para CNN Modelo 1
Epoch 1/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m3s[0m 12ms/step - accuracy: 0.3147 - loss: 2.7548 - val_accuracy: 0.8525 - val_loss: 0.6687
Epoch 2/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 12ms/step - accuracy: 0.8755 - loss: 0.5176 - val_accuracy: 0.9229 - val_loss: 0.3320
Epoch 3/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 11ms/step - accuracy: 0.9467 - loss: 0.2391 - val_accuracy: 0.9490 - val_loss: 0.2081
Epoch 4/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 11ms/step - accuracy: 0.9669 - loss: 0.1419 - val_accuracy: 0.9614 - val_loss: 0.1784
Epoch 5/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 10ms/step - accuracy: 0.9741 - loss: 0.1132 - val_accuracy: 0.9634 - val_loss: 0.1686
Epoch 6/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 10ms/step - accuracy: 0.9832 - loss: 0.0780 - val_accuracy: 0.9673 - val_loss: 0.1537
Epoch 7/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 10ms/step - accuracy: 0.9777 - loss: 0.0904 - val_accuracy: 0.9721 - val_loss: 0.1378
Epoch 8/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 10ms/step - accuracy: 0.9857 - loss: 0.0608 - val_accuracy: 0.9505 - val_loss: 0.1956
Epoch 9/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 10ms/step - accuracy: 0.9836 - loss: 0.0592 - val_accuracy: 0.9758 - val_loss: 0.1266
Epoch 10/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 10ms/step - accuracy: 0.9913 - loss: 0.0356 - val_accuracy: 0.9687 - val_loss: 0.1464
Exactitud en fold 2: 0.9687

Exactitud promedio para CNN Modelo 1: 0.9760 +/- 0.0073

Entrenando fold 1/2 para CNN Modelo 2
Epoch 1/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m6s[0m 22ms/step - accuracy: 0.2025 - loss: 3.0220 - val_accuracy: 0.8794 - val_loss: 0.5264
Epoch 2/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.8137 - loss: 0.6453 - val_accuracy: 0.9643 - val_loss: 0.1365
Epoch 3/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.9186 - loss: 0.2729 - val_accuracy: 0.9746 - val_loss: 0.0950
Epoch 4/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.9396 - loss: 0.1836 - val_accuracy: 0.9821 - val_loss: 0.0824
Epoch 5/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 21ms/step - accuracy: 0.9545 - loss: 0.1370 - val_accuracy: 0.9873 - val_loss: 0.0509
Epoch 6/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.9634 - loss: 0.1235 - val_accuracy: 0.9896 - val_loss: 0.0419
Epoch 7/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m4s[0m 21ms/step - accuracy: 0.9724 - loss: 0.0831 - val_accuracy: 0.9884 - val_loss: 0.0443
Epoch 8/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.9711 - loss: 0.0814 - val_accuracy: 0.9908 - val_loss: 0.0344
Epoch 9/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m4s[0m 21ms/step - accuracy: 0.9749 - loss: 0.0761 - val_accuracy: 0.9897 - val_loss: 0.0397
Epoch 10/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.9821 - loss: 0.0584 - val_accuracy: 0.9908 - val_loss: 0.0344
Exactitud en fold 1: 0.9908

Entrenando fold 2/2 para CNN Modelo 2
Epoch 1/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m6s[0m 22ms/step - accuracy: 0.1825 - loss: 3.1186 - val_accuracy: 0.8819 - val_loss: 0.4922
Epoch 2/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 21ms/step - accuracy: 0.8080 - loss: 0.6770 - val_accuracy: 0.9414 - val_loss: 0.2187
Epoch 3/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m4s[0m 21ms/step - accuracy: 0.8885 - loss: 0.3775 - val_accuracy: 0.9697 - val_loss: 0.1210
Epoch 4/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 23ms/step - accuracy: 0.9257 - loss: 0.2535 - val_accuracy: 0.9745 - val_loss: 0.1022
Epoch 5/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.9435 - loss: 0.1854 - val_accuracy: 0.9794 - val_loss: 0.0818
Epoch 6/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.9571 - loss: 0.1414 - val_accuracy: 0.9807 - val_loss: 0.0767
Epoch 7/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.9609 - loss: 0.1309 - val_accuracy: 0.9853 - val_loss: 0.0630
Epoch 8/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.9641 - loss: 0.1149 - val_accuracy: 0.9850 - val_loss: 0.0636
Epoch 9/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 22ms/step - accuracy: 0.9716 - loss: 0.0916 - val_accuracy: 0.9875 - val_loss: 0.0558
Epoch 10/10
[1m209/209[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 23ms/step - accuracy: 0.9716 - loss: 0.0896 - val_accuracy: 0.9860 - val_loss: 0.0573
Exactitud en fold 2: 0.9860

Exactitud promedio para CNN Modelo 2: 0.9884 +/- 0.0024
[34m[1mwandb[0m: [33mWARNING[0m WandbCallback is deprecated and will be removed in a future release. Please use the WandbMetricsLogger, WandbModelCheckpoint, and WandbEvalCallback callbacks instead. See https://docs.wandb.ai/guides/integrations/keras for more information.
[34m[1mwandb[0m: [33mWARNING[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
Epoch 1/10
[31mERROR[0m:    Exception in ASGI application
Traceback (most recent call last):
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\uvicorn\protocols\http\h11_impl.py", line 403, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\uvicorn\middleware\proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\fastapi\applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\applications.py", line 113, in __call__
    await self.middleware_stack(scope, receive, send)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\middleware\errors.py", line 187, in __call__
    raise exc
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\middleware\errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\middleware\cors.py", line 93, in __call__
    await self.simple_response(scope, receive, send, request_headers=headers)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\middleware\cors.py", line 144, in simple_response
    await self.app(scope, receive, send)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\middleware\exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\routing.py", line 74, in app
    await response(scope, receive, send)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\responses.py", line 158, in __call__
    await self.background()
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\background.py", line 41, in __call__
    await task()
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\background.py", line 28, in __call__
    await run_in_threadpool(self.func, *self.args, **self.kwargs)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\starlette\concurrency.py", line 39, in run_in_threadpool
    return await anyio.to_thread.run_sync(func, *args)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\anyio\to_thread.py", line 56, in run_sync
    return await get_async_backend().run_sync_in_worker_thread(
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\anyio\_backends\_asyncio.py", line 2441, in run_sync_in_worker_thread
    return await future
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\anyio\_backends\_asyncio.py", line 943, in run
    result = context.run(func, *args)
  File "C:\Users\Josehp\Downloads\traffic_sign_recognition-main\traffic_sign_recognition-main\backend\app\utils\training_pipeline.py", line 167, in train_and_evaluate
    self.model.fit(
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\keras\src\utils\traceback_utils.py", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\wandb\integration\keras\keras.py", line 667, in on_train_batch_end
    wandb.run.summary["graph"] = wandb.Graph.from_keras(self.model)
  File "c:\users\josehp\appdata\local\programs\python\python39\lib\site-packages\wandb\sdk\data_types\graph.py", line 357, in from_keras
    for in_layer in _nest(in_node.inbound_layers):
AttributeError: 'Node' object has no attribute 'inbound_layers'
[32mINFO[0m:     Shutting down
[32mINFO[0m:     Waiting for application shutdown.
[32mINFO[0m:     Application shutdown complete.
[32mINFO[0m:     Finished server process [[36m129908[0m]
